# -*- coding: utf-8 -*-
"""coleta.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qyElFT9jhIn6CSUyuvRESZEV_b3bLTKy
"""

!git clone https://github.com/marquisvictor/Optimized-Modified-GetOldTweets3-OMGOT
!pip install async-timeout
!pip install aiohttp
!pip install fake_useragent
!pip install aiohttp_socks
!pip install googletransx

"""# Snscraper"""

!pip3 install snscrape

import os
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')
os.chdir("/content/drive/MyDrive/carla/")

import snscrape.modules.twitter as sntwitter
import pandas as pd
import numpy as np

#Creating list to append tweet data to
tweets_list3=[ ]
 Using TwitterSearchScraper to scrape data and append tweets to list
for i,tweet in enumerate(sntwitter.TwitterSearchScraper('ebola until:2014-01-31 near:"Freetown" within:300km').get_items()):
    tweets_list3.append([tweet.date, tweet.id, tweet.content,tweet])

obj_tweet=[x[3] for x in tweets_list3]

tcooutlinks=[x.tcooutlinks if hasattr(x, 'tcooutlinks') else "-" for x in obj_tweet]
url=[x.url for x in obj_tweet]
date=[x.date for x in obj_tweet]
tzinfo=[x.tzinfo if hasattr(x, 'tzinfo') else "-" for x in obj_tweet]

content=[x.content if hasattr(x, 'content') else "-" for x in obj_tweet]
id=[x.id if hasattr(x, 'id') else "-" for x in obj_tweet]
username=[x.username  for x in obj_tweet]
outlinks=[x.outlinks  for x in obj_tweet]
outlinksss=[x.outlinksss  for x in obj_tweet]
tcooutlinks=[x.tcooutlinks  for x in obj_tweet]
tcooutlinksss=[x.tcooutlinksss  for x in obj_tweet]
date=obj_tweet=[x[0] for x in tweets_list3]

url="https://twitter.com/"
df3=pd.DataFrame({"url":url,"date":date,"content":content,"id":id,"username":username,"outlinks":outlinks,"outlinksss":outlinksss,"tcooutlinks":tcooutlinks,"tcooutlinksss":tcooutlinksss})
#.to_excel("tweets snsscraper.xlsx")

df3.to_csv("coleta_ebola.csv")

df3=df3.drop(["outlinks",	"outlinksss",	"tcooutlinks",	"tcooutlinksss"],axis=1).drop_duplicates()

df3.sort_values(by="date")

import re

def collect_mentions(i,df):
 mentions=re.findall(r'\@[^\s]*',df.iloc[i,2])
 result=[[df.iloc[i,4],df.iloc[i,1],x,i] for x in mentions]
 if result==[]:
    return(None)
 else:
   return(result)

lista_mencoes=[collect_mentions(i,df3) for i in range(len(df3))]
lista_mencoes=[x for x in lista_mencoes if x != None]
flat_list = [item for sublist in lista_mencoes for item in sublist]
ebola=pd.DataFrame(flat_list)
ebola.columns=["origem","data","mencao","label"]

ebola["mencao"]=ebola["mencao"].str[1:]

labels=pd.concat([ebola['origem'],ebola['mencao']])
labels=labels.reset_index()
labels['index']=0
labels=labels.drop_duplicates()
labels["index"]=range(labels.shape[0])

labels["index"]=range(labels.shape[0])
labels.columns=["id",'Label']


ebola2=ebola[["origem","mencao"]].replace({"mencao":labels.set_index("Label").to_dict()["id"]})

ebola2=ebola2[["origem","mencao"]].replace({"origem":labels.set_index("Label").to_dict()["id"]})


ebola2.columns=["Source","Target"]
ebola2["Type"]="Directed"
ebola2["Weight"]=1

ebola2.to_csv()

ebola2.to_csv("ebola_formato_gephi.csv",index=False)